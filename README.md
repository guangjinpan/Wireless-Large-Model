# Wireless-Large-Model
Papers related to "wireless large AI models (LAMs)" and wireless foundation models.

ğŸ“Œ *This list is continuously updated.*

Stay tuned and feel free to â­ star this repo to follow the latest progress.

ğŸ¤ *Open to collaboration and discussion!*

If you're interested in large model research, feel free to reach out for academic discussion or potential collaboration.

# ğŸ“¡ Wireless Large AI Models Paper List



## ğŸ“‚ Categories

### 1. ğŸ“¶ LAMâ€“Based Wireless Channel foundation model 
ç ”ç©¶ä½¿ç”¨å¤§æ¨¡å‹ï¼ˆå¦‚ Transformerã€Diffusion ç­‰ï¼‰è¿›è¡Œæ— çº¿ä¿¡é“å»ºæ¨¡ã€ä¿¡é“ä¼°è®¡ã€ç¯å¢ƒå»ºæ¨¡ç­‰ã€‚

| Title | Authors | Venue | Year | Link |
|-------|---------|-------|------|------|
| DeepMIMO-LLM: Large Language Models for Channel Modeling | Liu et al. | arXiv | 2024 | [PDF](https://arxiv.org/abs/xxxx) |
| DiffChannel: Diffusion Models for Wireless Channels | Zhang et al. | ICC | 2024 | [PDF](https://arxiv.org/abs/xxxx) |

---

### 2. ğŸ§  LAMâ€“Driven Network Optimization  
å…³æ³¨åˆ©ç”¨å¤§æ¨¡å‹è¿›è¡Œç½‘ç»œèµ„æºåˆ†é…ã€è°ƒåº¦ã€åŠŸæ§ã€æ™ºèƒ½å†³ç­–ç­‰æ–¹é¢çš„ä¼˜åŒ–ã€‚

| Title | Authors | Venue | Year | Link |
|-------|---------|-------|------|------|
| Graph LLMs for Network Control | Wang et al. | INFOCOM | 2025 | [PDF](https://arxiv.org/abs/xxxx) |
| Policy Tuning with LLMs for 5G | Chen et al. | NeurIPS | 2023 | [PDF](https://arxiv.org/abs/xxxx) |

---

### 3. ğŸ—£ï¸ LAMâ€“Enabled Semantic Communication  

| Title | Authors | Venue | Year | Link |
|-------|---------|-------|------|------|
| SemCom-GPT: LLMs for Semantic Transmission | Li et al. | arXiv | 2024 | [PDF](https://arxiv.org/abs/xxxx) |
| End-to-End Semantic Communication with LLMs | Zhao et al. | ICASSP | 2023 | [PDF](https://arxiv.org/abs/xxxx) |

---

## âœ¨ Contributing

Welcome to contribute!  
Please follow the format:  
`| Title | Authors | Venue | Year | Link |`  
Open a pull request or submit an issue if you want to add papers.

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

Pull requests are welcome. Please follow the format and add relevant papers.
